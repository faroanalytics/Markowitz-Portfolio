{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "from pandas_datareader import data\n",
    "import yfinance as yf\n",
    "from matplotlib import style\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "\n",
    "import scipy.optimize as sco\n",
    "\n",
    "yf.pdr_override()\n",
    "\n",
    "plt.style.use('ggplot')\n",
    "np.random.seed(42)\n",
    "\n",
    "portchoice = 8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#pull in tickers and get rid of ones with weird symbols\n",
    "\n",
    "df2 = pd.read_csv('C:/Users/danal/Desktop/Tickers101118.csv', header=None)\n",
    "df2.columns = ['Tickers']\n",
    "df2 = df2[~df2['Tickers'].str.contains('\\^') ]\n",
    "df2 = df2[~df2['Tickers'].str.contains('\\.') ]\n",
    "df2 = df2[~df2['Tickers'].str.contains('\\-') ]\n",
    "df2 = df2.values.tolist()\n",
    "len(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#   My datafetch below   ########################\n",
    "df3=pd.DataFrame()\n",
    "df4=pd.DataFrame()\n",
    "\n",
    "for row in df2:\n",
    "    try:\n",
    "        df3=yf.download(row,start=\"2018-8-16\",end=\"2019-08-16\")\n",
    "        df3adjclose=pd.DataFrame(df3['Adj Close'])\n",
    "        df3adjclose.columns = [row]\n",
    "        df4=pd.concat([df4, df3adjclose], axis = 1)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#can use if pickled from spyder\n",
    "df4 = pd.read_pickle(\"C:/Users/danal/Desktop/allcomps81919.pkl\")\n",
    "#df4.to_pickle(\"C:/Users/danal/Desktop/allcomps81919.pkl\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4t = df4.T\n",
    "df4t = df4t[~df4t.index.duplicated(keep='first')]\n",
    "df4 = df4t.T\n",
    "df4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4rtns_1year = df4.pct_change()\n",
    "df4rtns_1year.dropna(axis=0, how='all', inplace=True)\n",
    "df4rtns_1year.dropna(axis=1, how='any', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4rtns_1year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#returns and standard deviation for 1 year\n",
    "df4std_1year = pd.DataFrame(np.std(df4rtns_1year, axis=0), columns = ['Stand_Dev'])\n",
    "df4std_1year = df4std_1year.reset_index()\n",
    "df4std_1year.columns = ['Tickers', 'Stand_Dev']\n",
    "df4std_1year = df4std_1year.set_index('Tickers', drop = True)\n",
    "\n",
    "\n",
    "df4_avertn_1year = np.mean(df4rtns_1year, axis = 0)\n",
    "df4_avertn_1year = df4_avertn_1year.reset_index()\n",
    "df4_avertn_1year.columns = ['Tickers', 'Ave_Return']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_avertn_1year.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4_avertn_1year['Annualized_Rtn'] = df4_avertn_1year[\"Ave_Return\"] * 252"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4std_1year['Annualized_StdDev'] = df4std_1year['Stand_Dev'] * np.sqrt(252)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StkDataFrame = df4_avertn_1year.merge(df4std_1year, on=\"Tickers\")\n",
    "StkDataFrame[\"Sharpe_Ratio\"] = (StkDataFrame[\"Annualized_Rtn\"]-.026)/StkDataFrame[\"Annualized_StdDev\"]\n",
    "StkDataFrame.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StkDataFrame = StkDataFrame[(StkDataFrame[\"Annualized_StdDev\"] >=0) & (StkDataFrame[\"Annualized_StdDev\"] <=.5)]\n",
    "StkDataFrame = StkDataFrame[(StkDataFrame[\"Sharpe_Ratio\"] >=-3) & (StkDataFrame[\"Sharpe_Ratio\"] <=3)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "StkDataFrame.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sharpe ratio histogram\n",
    "plt.hist(StkDataFrame['Sharpe_Ratio'], bins=25);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Sharpe 1 year where the value is .08 or higher\n",
    "Sharpegood = StkDataFrame[(StkDataFrame['Sharpe_Ratio']>=1) & (StkDataFrame['Sharpe_Ratio']<=3)]\n",
    "len(Sharpegood)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Sharpe1yrlist = Sharpegood['Tickers'].tolist()\n",
    "Sharpe1yrlist = pd.DataFrame(Sharpe1yrlist)\n",
    "Sharpe1yrlist.columns = ['Ticker']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portuniverse=pd.DataFrame()\n",
    "\n",
    "for x in range(0, 1000):\n",
    "    Portfolioselect = Sharpe1yrlist.sample(n=portchoice,replace=False)\n",
    "    Portfolioselect = Portfolioselect.iloc[:, 0].tolist()\n",
    "    Portfolioselectrtn = df4rtns_1year[Portfolioselect]\n",
    "    df1yrcovport = Portfolioselectrtn.cov()\n",
    "    df1yrcovport1 = df1yrcovport.rename_axis(None).rename_axis(None, axis=1)\n",
    "    df1yrcovport2 = df1yrcovport1.stack().reset_index()\n",
    "    df1yrcovport2.fillna(value = 0, inplace=True)\n",
    "    df1yrcovport2['Covariance'] = df1yrcovport2.iloc[:, 2:len(df1yrcovport2)].sum(axis=1)\n",
    "    df1yrcovport2 = df1yrcovport2[['level_0', 'level_1', 'Covariance']]\n",
    "    df1yrcovport2 = df1yrcovport2.rename(columns={'level_0': 'Company_A', 'level_1': 'Company_B'})\n",
    "    #df1yrcovport2 = df1yrcovport2[df1yrcovport2.Covariance != 1]\n",
    "    \n",
    "\n",
    "    if (df1yrcovport2['Covariance'] <= .005).all() or (df1yrcovport2['Covariance'] >= -.005).all() :\n",
    "        Portfolioselect =  pd.DataFrame(Portfolioselect)\n",
    "        Portfolioselect = Portfolioselect.T\n",
    "        portuniverse = pd.concat([portuniverse, Portfolioselect], ignore_index = True)\n",
    "    else:\n",
    "        pass\n",
    "\n",
    "#portuniverse.columns = ['stk0','stk1','stk2','stk3','stk4','stk5','stk6','stk7']    \n",
    "portuniverse = portuniverse.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "portuniverse.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#look for duplicate portfolios\n",
    "\n",
    "\"\"\"portuniverse['stklist'] = portuniverse[['stk0','stk1','stk2','stk3','stk4','stk5','stk6','stk7']].values.tolist()\n",
    "portuniverse['stklist'] = portuniverse['stklist'].sort_values().apply(lambda x: sorted(x))\n",
    "portuniverse['totlist'] = ['_'.join(map(str, i)) for i in portuniverse['stklist']]\n",
    "portuniverse = portuniverse.drop_duplicates(subset='totlist', keep='first')\n",
    "portuniverse = portuniverse.drop(['stklist', 'totlist'], axis = 1)\n",
    "portuniverse = portuniverse.reset_index(drop = True)\n",
    "portuniverse\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np, numpy.random\n",
    "\n",
    "Portfoliolist = pd.DataFrame()\n",
    "Weightingfin = pd.DataFrame()\n",
    "Portfoliodetail = pd.DataFrame(columns = [\"Tickers\", \"Weights\", \"Returns\", \"Stand_Dev\", \"Portfolio_Num\", \"Iteration\"])\n",
    "\n",
    "for row in range(0,len(portuniverse)):\n",
    "    portfoliox = portuniverse.loc[row]\n",
    "    portfolioxdfi = pd.DataFrame(portfoliox)\n",
    "    portfolioxdfi.columns = ['Tickers']\n",
    "    \n",
    "    for x in range (0,100):\n",
    "        weightsdf = pd.DataFrame(np.random.dirichlet(np.ones(portchoice),size=1))\n",
    "        weightsdf = round(weightsdf,3)\n",
    "        weightsdf = weightsdf.T\n",
    "        weightsdf.columns = ['Weights']\n",
    "        portfolioxdfi2 = pd.concat([portfolioxdfi, weightsdf], axis = 1)\n",
    "        portfolioxdfirtn = pd.merge(portfolioxdfi2, df4_avertn_1year, on='Tickers', how='left')\n",
    "        portfolioxdfirtn = pd.merge(portfolioxdfirtn, df4std_1year, on='Tickers', how='left')\n",
    "        portfolioxdfirtn['Portfolio_Num'] = row\n",
    "        portfolioxdfirtn['Iteration'] = x\n",
    "        \n",
    "        Portfoliodetail = pd.concat([Portfoliodetail, portfolioxdfirtn], axis = 0)\n",
    "        \n",
    "        portfolioxdfirtnval = portfolioxdfirtn['Weights'] * portfolioxdfirtn['Annualized_Rtn']\n",
    "        portfolioxdfirtnvalf = np.sum(portfolioxdfirtnval)\n",
    "        \n",
    "        Portfolioselectsp = portfolioxdfirtn.iloc[:, 0].tolist()\n",
    "        Portfolioselectrtns = df4rtns_1year[Portfolioselectsp]\n",
    "        Portfolioselectcovm = Portfolioselectrtns.cov()\n",
    "        Portfoliocovariance = np.dot(portfolioxdfirtn['Weights'].T, Portfolioselectcovm)\n",
    "        Portfoliocovariance = np.sqrt(np.dot(Portfoliocovariance, portfolioxdfirtn['Weights']))\n",
    "        SharpeRatio = ((portfolioxdfirtnvalf - .026)/(np.sqrt(Portfoliocovariance)))\n",
    "        portmetrics = pd.DataFrame([row, portfolioxdfirtnvalf, Portfoliocovariance, SharpeRatio]).T\n",
    "        Portfoliolist = pd.concat([Portfoliolist,portmetrics], axis = 0)\n",
    "        Weighting = weightsdf.T\n",
    "        Weighting['Portfolio'] = row\n",
    "        Weighting['Iteration'] = x\n",
    "        Weighting['Portfolio_Covariance'] = Portfoliocovariance\n",
    "        Weightingfin = pd.concat([Weightingfin, Weighting], axis = 0)\n",
    "\n",
    "Portfoliolist.columns = ['Portfolio_Number', 'Portfolio_Return', 'Portfolio_Covariance', 'Sharpe_Ratio']\n",
    "Weightingfin = Weightingfin.reset_index(drop = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df4 = pd.read_pickle(\"C:/Users/danal/Desktop/portfoliolist81919.pkl\")\n",
    "#df4.to_pickle(\"C:/Users/danal/Desktop/portfoliolist81919.pkl\")\n",
    "\n",
    "#!pip install palettable\n",
    "\n",
    "plt.subplots(figsize=(20,15))\n",
    "\n",
    "sns.scatterplot(x=\"Portfolio_Covariance\", y=\"Portfolio_Return\",\n",
    "                hue=\"Sharpe_Ratio\",\n",
    "                palette='plasma_r',\n",
    "                linewidth=0,\n",
    "                data=Portfoliolist);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Portfoliolist.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumVar = Portfoliolist[Portfoliolist['Portfolio_Covariance'] == min(Portfoliolist['Portfolio_Covariance'])]\n",
    "MinimumVar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MinimumVarPort = MinimumVar['Portfolio_Number'].astype(int)\n",
    "MinimumVarPort2 = portuniverse.iloc[MinimumVarPort]\n",
    "MinimumVarPort2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Portfoliolist.to_pickle('D:/NewMexicoData/Portlist.pkl')\n",
    "#Weightingfin.to_pickle('D:/NewMexicoData/Weightingfinlist.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Weightingfin[Weightingfin['Portfolio_Covariance'] == min(Weightingfin['Portfolio_Covariance'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
